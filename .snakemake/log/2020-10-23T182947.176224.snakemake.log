Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	mars_rmd
	2

[Fri Oct 23 18:29:47 2020]
rule mars_rmd:
    input: data/count.txt.gz, data/expdesign.txt.gz
    output: results/mars_rmd.html
    log: logs/mars_rmd.log
    jobid: 8
    benchmark: benchmark/mars_rmd.txt

[Fri Oct 23 18:29:50 2020]
Finished job 8.
1 of 2 steps (50%) done

[Fri Oct 23 18:29:50 2020]
localrule all:
    input: results/mars.ipynb, results/mars.RData, results/mars.html, results/papermill_2.ipynb, results/papermill_3.ipynb, results/papermill_4.ipynb, results/papermill_5.ipynb, results/papermill_6.ipynb, results/mars_rmd.html
    jobid: 0

[Fri Oct 23 18:29:50 2020]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /Users/tsuyusakikouki/Desktop/elwood/Dev/preprocess-exercise/.snakemake/log/2020-10-23T182947.176224.snakemake.log
